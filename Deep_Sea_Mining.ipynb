{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "649dc2f5",
   "metadata": {},
   "source": [
    "## Kombinierter DataFrame aus allen relevanten Sheets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2fb190a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Kombinierter Datensatz: 545 Zeilen, 230 Spalten\n",
      "                               Functional Impact Unnamed: 1 Unnamed: 2  \\\n",
      "0                                  1 = No Impact        NaN        NaN   \n",
      "1                    2 = Single/Multiple Species        NaN        NaN   \n",
      "2      3 = Single Trophic Level/Functional Group        NaN        NaN   \n",
      "3  4 = Multiple Trophic Levels/Functional Groups        NaN        NaN   \n",
      "4                           5 = Entire Community        NaN        NaN   \n",
      "\n",
      "      HabRem      SedComp        Homo      Hetero      OrgEnr     SedPore  \\\n",
      "0  Nodule Bed  Nodule Bed  Nodule Bed  Nodule Bed  Nodule Bed  Nodule Bed   \n",
      "1      FunImp      FunImp      FunImp      FunImp      FunImp      FunImp   \n",
      "2   HabAltRem   HabAltRem   HabAltRem   HabAltRem   HabAltRem   HabAltRem   \n",
      "3           5           4           4         NaN           4           4   \n",
      "4           5           2         NaN         NaN         NaN           5   \n",
      "\n",
      "       AltMin  ... Unnamed: 105 Unnamed: 106 Unnamed: 107 Unnamed: 108 WPSP.5  \\\n",
      "0  Nodule Bed  ...          NaN          NaN          NaN          NaN    NaN   \n",
      "1      FunImp  ...          NaN          NaN          NaN          NaN    NaN   \n",
      "2   HabAltRem  ...          NaN          NaN          NaN          NaN    NaN   \n",
      "3           5  ...          NaN          NaN          NaN          NaN    NaN   \n",
      "4         NaN  ...          NaN          NaN          NaN          NaN    NaN   \n",
      "\n",
      "  Unnamed: 110 Unnamed: 111 Unnamed: 112 Unnamed: 113 Unnamed: 114  \n",
      "0          NaN          NaN          NaN          NaN          NaN  \n",
      "1          NaN          NaN          NaN          NaN          NaN  \n",
      "2          NaN          NaN          NaN          NaN          NaN  \n",
      "3          NaN          NaN          NaN          NaN          NaN  \n",
      "4          NaN          NaN          NaN          NaN          NaN  \n",
      "\n",
      "[5 rows x 230 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 1. Lokaler Pfad zur Excel-Datei\n",
    "dateipfad = r\"C:\\Users\\denni\\OneDrive\\Dokumente\\Projekt\\Suppl. ERA_Data.csv.xlsx\"\n",
    "\n",
    "# 2. Alle Sheets einlesen\n",
    "alle_sheets = pd.read_excel(dateipfad, sheet_name=None)\n",
    "\n",
    "# 3. Nicht relevante Sheets ausschlieÃŸen\n",
    "relevante_sheets = {name: df for name, df in alle_sheets.items() if name not in [\"Meta\", \"Blanks\"]}\n",
    "\n",
    "# 4. Alle relevanten Sheets in eine Liste aufnehmen â€“ Sheet-Namen als Spalte hinzufÃ¼gen\n",
    "dataframes = []\n",
    "for name, df in relevante_sheets.items():\n",
    "    df = df.copy()\n",
    "    df[\"Sheet\"] = name  # Herkunfts-Info als Spalte\n",
    "    dataframes.append(df)\n",
    "\n",
    "# 5. ZusammenfÃ¼hren zu einem groÃŸen Master-DataFrame\n",
    "df_master = pd.concat(dataframes, ignore_index=True)\n",
    "\n",
    "# 6. Leere Zeilen und Spalten entfernen\n",
    "df_master.dropna(axis=0, how=\"all\", inplace=True)\n",
    "df_master.dropna(axis=1, how=\"all\", inplace=True)\n",
    "\n",
    "# 7. Doppelte Zeilen entfernen (optional, aber sinnvoll)\n",
    "df_master.drop_duplicates(inplace=True)\n",
    "\n",
    "# 8. Ergebnis anzeigen\n",
    "print(f\"âœ… Kombinierter Datensatz: {df_master.shape[0]} Zeilen, {df_master.shape[1]} Spalten\")\n",
    "print(df_master.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c444987",
   "metadata": {},
   "source": [
    "## Aktuellen Zeilenumfang prÃ¼fen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "64e0b489",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aktuelle Anzahl Zeilen: 545\n"
     ]
    }
   ],
   "source": [
    "print(f\"Aktuelle Anzahl Zeilen: {df_master.shape[0]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1939f9b",
   "metadata": {},
   "source": [
    "## Option 1: Kombinatorische VervielfÃ¤ltigung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7f8de698",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸŽ¯ Neuer Umfang: 8045 Zeilen\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "import random\n",
    "\n",
    "# Beispielhafte Listen aus deinem Meta-Sheet\n",
    "habitats = [\"NodSed\", \"NodHard\", \"SulCoral\", \"CrustBP\", \"CrustSed\"]\n",
    "risiken = [\"VehSound\", \"VehLight\", \"SedComp\", \"HabRem\", \"EleRad\"]\n",
    "indikatoren = [\"ImpactScore\", \"ResistanceIndex\", \"RecoveryTime\"]\n",
    "\n",
    "# Alle Kombinationen erstellen\n",
    "kombis = list(itertools.product(habitats, risiken, indikatoren))\n",
    "\n",
    "# Dummy-Daten erzeugen (du kannst auch echte Verteilungen nehmen)\n",
    "daten_erweitert = []\n",
    "for h, r, i in kombis:\n",
    "    for _ in range(100):  # 100 Wiederholungen = ca. 10.000 Zeilen\n",
    "        daten_erweitert.append({\n",
    "            \"Habitat\": h,\n",
    "            \"RiskSource\": r,\n",
    "            \"Indicator\": i,\n",
    "            \"Value\": round(random.uniform(0, 1), 3),\n",
    "            \"Sheet\": \"Synthesized\"\n",
    "        })\n",
    "\n",
    "# In DataFrame umwandeln und anhÃ¤ngen\n",
    "df_erweitert = pd.DataFrame(daten_erweitert)\n",
    "df_master_extended = pd.concat([df_master, df_erweitert], ignore_index=True)\n",
    "\n",
    "print(f\"ðŸŽ¯ Neuer Umfang: {df_master_extended.shape[0]} Zeilen\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4994ea56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”§ Es fehlen noch 1955 Zeilen bis 10.000.\n",
      "âœ… Finaler Umfang: 10000 Zeilen\n"
     ]
    }
   ],
   "source": [
    "# Berechne, wie viele Zeilen fehlen\n",
    "ziel_anzahl = 10000\n",
    "aktuell = df_master_extended.shape[0]\n",
    "fehlen = ziel_anzahl - aktuell\n",
    "\n",
    "print(f\"ðŸ”§ Es fehlen noch {fehlen} Zeilen bis 10.000.\")\n",
    "\n",
    "# Erzeuge weitere Zufallsdaten, um auf genau 10.000 zu kommen\n",
    "zusatzdaten = []\n",
    "for _ in range(fehlen):\n",
    "    zusatzdaten.append({\n",
    "        \"Habitat\": random.choice(habitats),\n",
    "        \"RiskSource\": random.choice(risiken),\n",
    "        \"Indicator\": random.choice(indikatoren),\n",
    "        \"Value\": round(random.uniform(0, 1), 3),\n",
    "        \"Sheet\": \"Synthesized+\"\n",
    "    })\n",
    "\n",
    "# In DataFrame umwandeln und hinzufÃ¼gen\n",
    "df_zusatz = pd.DataFrame(zusatzdaten)\n",
    "df_final = pd.concat([df_master_extended, df_zusatz], ignore_index=True)\n",
    "\n",
    "print(f\"âœ… Finaler Umfang: {df_final.shape[0]} Zeilen\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6e5918e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“Š Anzahl Zeilen im finalen DataFrame: 10000\n"
     ]
    }
   ],
   "source": [
    "# Zeilenanzahl ausgeben\n",
    "print(\"ðŸ“Š Anzahl Zeilen im finalen DataFrame:\", df_final.shape[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9c2ba912",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Functional Impact Unnamed: 1 Unnamed: 2     HabRem      SedComp        Homo  \\\n",
      "0     1 = No Impact        NaN        NaN  Nodule Bed  Nodule Bed  Nodule Bed   \n",
      "\n",
      "       Hetero      OrgEnr     SedPore      AltMin  ... WPSP.5 Unnamed: 110  \\\n",
      "0  Nodule Bed  Nodule Bed  Nodule Bed  Nodule Bed  ...    NaN          NaN   \n",
      "\n",
      "  Unnamed: 111 Unnamed: 112 Unnamed: 113 Unnamed: 114 Habitat RiskSource  \\\n",
      "0          NaN          NaN          NaN          NaN     NaN        NaN   \n",
      "\n",
      "  Indicator Value  \n",
      "0       NaN   NaN  \n",
      "\n",
      "[1 rows x 234 columns]\n",
      "     Functional Impact Unnamed: 1 Unnamed: 2 HabRem  SedComp Homo Hetero  \\\n",
      "9999               NaN        NaN        NaN     NaN     NaN  NaN    NaN   \n",
      "\n",
      "     OrgEnr SedPore AltMin  ... WPSP.5 Unnamed: 110 Unnamed: 111 Unnamed: 112  \\\n",
      "9999    NaN     NaN    NaN  ...    NaN          NaN          NaN          NaN   \n",
      "\n",
      "     Unnamed: 113 Unnamed: 114   Habitat RiskSource        Indicator  Value  \n",
      "9999          NaN          NaN  SulCoral     EleRad  ResistanceIndex  0.703  \n",
      "\n",
      "[1 rows x 234 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df_final.head(1))     # erste Zeile\n",
    "print(df_final.tail(1))     # letzte Zeile\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
